{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "58034_Lab02_Pyrates",
      "provenance": [],
      "authorship_tag": "ABX9TyNykesLzpAQyaV/2B6xlx1c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karldeguzman32/CpE-AIML/blob/main/58034_Lab02_Pyrates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc24h680fMks"
      },
      "source": [
        "For the final cases analysis we will be looking at series of equations building up a single feed-forward computation of a logistic regression. The case will not require you to learn fully what is logistic regression. \n",
        "\n",
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{, } \n",
        "Y = \\begin{bmatrix} \n",
        "y^{(1)} \\\\ \n",
        "y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "y^{(m)} \\\\\n",
        "\\end{bmatrix} \\text{, and } \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "The dataset $X$ has $m$ entries with $n$ features while $Y$ is the vector containing the groud truths of a the entries of $X$, and $\\theta$ are the parameters or weights of the vectors. We first compute the vector product of the dataset and the parameters as:\n",
        "$$ z = x^{(i)}\\theta^{(i)} = X\\cdot \\theta\\\\_{\\text{Eq. 3.1}}$$\n",
        "We then solve for the hypothesis of the logistic regression alogrithm as:\n",
        "\n",
        "$$ h_\\theta(x) = g(z)\\\\_{\\text{Eq. 3.2}}$$\n",
        "\n",
        "Where $g$ is an acitvation function that maps the values of the hypothesis vector between a range of 0 and 1. We computed the activation as a sigmoid function:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}\\\\_{\\text{Eq. 3.3}}$$\n",
        "Finally we compute the loss of the logistic regression algorithm using $J$. Wheras $J(\\theta)$ is a function that computes the logistic loss of the hypothesis with respect to the ground truths $y$. it is then computed as:\n",
        "$$J(\\theta) = \\frac{1}{m} \\sum^m_{i=0}=[-y^{(i)}\\log({h_{\\theta}(x^{(i)})})-(1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))]\\\\_{\\text{Eq. 3.4}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhodMzdUfQ5V"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LRegression:\n",
        "  def __init__(self, dset_X, gtruths_Y, weights_T):\n",
        "    self.dset = dset_X\n",
        "    self.gtruths = gtruths_Y\n",
        "    self.weights = weights_T\n",
        "\n",
        "  def vect_prod(self): # EQ 3.1\n",
        "    self.prod_z = np.dot(self.dset, self.weights)\n",
        "    return self.prod_z\n",
        "\n",
        "  def hypothesis(self): #EQ 3.2 & 3.3\n",
        "    self.sigmoid_function = 1 / (1 + np.exp(-(self.prod_z)))\n",
        "    return self.sigmoid_function\n",
        "\n",
        "  def logistic_loss(self): #EQ 3.4\n",
        "    m = self.dset.shape[0]\n",
        "    loss = (1/m) * np.dot(self.dset.T, (self.sigmoid_function - self.gtruths))\n",
        "    return loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d90vGy1bfW6U"
      },
      "source": [
        "X = np.array([1,2,3,4])\n",
        "theta = np.array([5,6,7,8])\n",
        "y = np.array([9,10,11,12])\n",
        "Lregression_class = LRegression(X, y, theta)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU1M48awfY3j",
        "outputId": "b96b29b1-9192-4199-aac9-c00a1050d6ec"
      },
      "source": [
        "regression = LRegression(X, y, theta)\n",
        "regression.vect_prod()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R8e-vMRfZ-W",
        "outputId": "cda6ff15-4e3c-4862-8841-ab5f2b49e330"
      },
      "source": [
        "regression.hypothesis()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzRMOINdfbO9",
        "outputId": "fd8332b5-6681-4a40-aec6-c63b71c72a04"
      },
      "source": [
        "regression.logistic_loss()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-25.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7_fpof-fcXX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}